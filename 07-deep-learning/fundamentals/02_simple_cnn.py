"""
Simple CNN for Image Classification

Build a Convolutional Neural Network from scratch (conceptually).
Learn why CNNs dominate computer vision.

Install: poetry add torch torchvision pillow
Run: poetry run python 07-deep-learning/fundamentals/02_simple_cnn.py
"""

import random
import math
from typing import List, Tuple


# ============================================================================
# 1. Why CNNs? The Problem with Regular Neural Networks
# ============================================================================

def demo_why_cnns():
    """
    Why Convolutional Neural Networks for images?
    
    INTUITION - The Photo Detective Problem:
    
    Regular Neural Network (Fully Connected):
    "Look at every single pixel individually, find the cat"
    
    Problem with 224√ó224 color image:
    - 224 √ó 224 √ó 3 = 150,528 pixels
    - First layer needs 150,528 √ó 1000 = 150 MILLION weights!
    - Can't learn patterns (edge of cat's ear could be anywhere)
    - Overfits like crazy
    
    CNN Approach:
    "Scan image with small filters, detect patterns locally"
    
    Benefits:
    - Finds edges regardless of position (translation invariant)
    - Dramatically fewer parameters (efficient!)
    - Learns hierarchy: edges ‚Üí shapes ‚Üí objects
    
    Real Analogy - Finding Waldo:
    
    Bad approach (fully connected):
    "Memorize every possible position of Waldo"
    ‚Üí Need to see Waldo in EVERY location
    
    Good approach (CNN):
    "Learn what Waldo looks like (red/white stripes, hat, glasses)"
    ‚Üí Find Waldo anywhere in the image!
    
    WHY CNNS DOMINATE COMPUTER VISION:
    
    1. Translation Invariance:
       Cat in top-left or bottom-right? Same detection!
       
    2. Parameter Sharing:
       One filter scans entire image (efficient)
       
    3. Hierarchical Learning:
       Layer 1: Edges (horizontal, vertical, diagonal)
       Layer 2: Textures (fur, scales, feathers)
       Layer 3: Parts (ears, eyes, nose)
       Layer 4: Objects (cat, dog, bird)
    
    Real Impact:
    - ImageNet 2012: AlexNet (CNN) wins by huge margin
    - Before: 75% accuracy, After: 85%+
    - Started deep learning revolution!
    """
    print("=" * 70)
    print("1. Why CNNs for Images?")
    print("=" * 70)
    print()
    print("üí≠ INTUITION: Finding Waldo")
    print()
    print("   ‚ùå Bad Approach (Fully Connected):")
    print("      'Memorize Waldo in every possible position'")
    print("      ‚Ä¢ Need 1000s of training examples")
    print("      ‚Ä¢ Waldo at new position? Model fails!")
    print("      ‚Ä¢ Parameters: 150 MILLION for 224√ó224 image")
    print()
    print("   ‚úÖ Good Approach (CNN):")
    print("      'Learn what Waldo looks like'")
    print("      ‚Ä¢ Red/white stripes, hat, glasses")
    print("      ‚Ä¢ Scan image, find pattern anywhere")
    print("      ‚Ä¢ Parameters: 10,000 (99% reduction!)")
    print()
    
    print("üìä The Numbers:")
    print()
    print("   Image: 224√ó224 RGB (224 √ó 224 √ó 3 = 150,528 pixels)")
    print()
    print("   Fully Connected Network:")
    print("   ‚Ä¢ Input: 150,528 neurons")
    print("   ‚Ä¢ Hidden: 1,000 neurons")
    print("   ‚Ä¢ Parameters: 150,528 √ó 1,000 = 150,528,000")
    print("   ‚Ä¢ Problems:")
    print("     - Overfits (too many parameters)")
    print("     - Can't generalize to new positions")
    print("     - Slow to train")
    print()
    print("   CNN:")
    print("   ‚Ä¢ Filters: 3√ó3 size, 32 filters")
    print("   ‚Ä¢ Parameters per filter: 3 √ó 3 √ó 3 = 27")
    print("   ‚Ä¢ Total: 32 √ó 27 = 864 parameters")
    print("   ‚Ä¢ Benefits:")
    print("     - Generalizes (finds patterns anywhere)")
    print("     - Fast to train")
    print("     - State-of-the-art results")
    print()
    
    print("üéØ Real Example: Cat Detection")
    print()
    print("   Fully Connected:")
    print("   ‚Ä¢ Learns: 'Cat has pixels at positions (12,45), (13,45)...'")
    print("   ‚Ä¢ New cat photo with cat in different spot? FAILS")
    print()
    print("   CNN:")
    print("   ‚Ä¢ Learns: 'Cat has triangular ears, whiskers, fur texture'")
    print("   ‚Ä¢ New cat photo in any position? SUCCESS ‚úì")
    print()
    
    print("üß† How CNNs Learn Hierarchy:")
    print()
    print("   Layer 1 (Edges):")
    print("   ‚Ä¢ Horizontal edge detector: |‚Äæ‚Äæ‚Äæ|")
    print("   ‚Ä¢ Vertical edge detector:   | | |")
    print("   ‚Ä¢ Diagonal edge detector:   |Ôºè|")
    print()
    print("   Layer 2 (Textures):")
    print("   ‚Ä¢ Combine edges ‚Üí Fur pattern")
    print("   ‚Ä¢ Combine edges ‚Üí Scale pattern")
    print("   ‚Ä¢ Combine edges ‚Üí Feather pattern")
    print()
    print("   Layer 3 (Parts):")
    print("   ‚Ä¢ Combine textures ‚Üí Cat ear")
    print("   ‚Ä¢ Combine textures ‚Üí Dog nose")
    print("   ‚Ä¢ Combine textures ‚Üí Bird beak")
    print()
    print("   Layer 4 (Objects):")
    print("   ‚Ä¢ Combine parts ‚Üí Cat!")
    print("   ‚Ä¢ Combine parts ‚Üí Dog!")
    print("   ‚Ä¢ Combine parts ‚Üí Bird!")
    print()
    
    print("üí° Key Innovation: Convolutional Filters")
    print()
    print("   Filter = Small pattern detector (e.g., 3√ó3)")
    print("   Slides across image, looking for pattern")
    print()
    print("   Example: Vertical Edge Detector")
    print("   Filter:    Image section:    Response:")
    print("   [-1 0 1]   [0 0 255]        High!")
    print("   [-1 0 1] * [0 0 255]  ‚Üí     (Found")
    print("   [-1 0 1]   [0 0 255]         edge!)")
    print()
    print("   Same filter scans ENTIRE image")
    print("   Finds vertical edges everywhere (efficient!)")


# ============================================================================
# 2. Convolution Operation
# ============================================================================

def demo_convolution():
    """
    Convolution: Sliding a filter over an image
    
    INTUITION - The Scanner Metaphor:
    
    You're proofreading a document for typos.
    
    Bad way:
    Read entire page at once (overwhelming!)
    
    Good way:
    Use a reading guide (ruler under each line)
    Scan line by line, check for errors
    
    Convolution is like the reading guide:
    - Small filter (3√ó3) scans image
    - Checks each local region
    - Detects patterns (edges, corners, textures)
    
    How It Works:
    
    1. Place filter on top-left of image
    2. Multiply filter values √ó image values
    3. Sum up results ‚Üí Single output value
    4. Slide filter right, repeat
    5. When reach end of row, go down and repeat
    
    Example: Edge Detection
    
    Image (grayscale):
    [0 0 0 255 255]  ‚Üê Left side dark, right side bright
    [0 0 0 255 255]
    [0 0 0 255 255]
    
    Vertical Edge Filter:
    [-1  0  1]
    [-1  0  1]
    [-1  0  1]
    
    Slide filter across image:
    - Over dark region: 0 (no edge)
    - Over edge: 765 (strong edge!)
    - Over bright region: 0 (no edge)
    
    Output shows WHERE the edges are!
    """
    print("\n" + "=" * 70)
    print("2. Convolution Operation")
    print("=" * 70)
    print()
    print("üí≠ INTUITION: Proofreading with a Reading Guide")
    print()
    print("   ‚ùå Read entire page at once:")
    print("      Too much information, miss errors")
    print()
    print("   ‚úÖ Use reading guide (ruler):")
    print("      Focus on one line at a time")
    print("      Scan systematically, catch every typo")
    print()
    print("   Convolution = Reading guide for images!")
    print("   Small filter scans image, detects patterns")
    print()
    
    # Simple edge detection example
    print("üéØ Example: Vertical Edge Detection")
    print()
    
    # Simple 5x5 image (dark left, bright right)
    image = [
        [0, 0, 0, 255, 255],
        [0, 0, 0, 255, 255],
        [0, 0, 0, 255, 255],
        [0, 0, 0, 255, 255],
        [0, 0, 0, 255, 255]
    ]
    
    # 3x3 vertical edge filter
    filter_vert = [
        [-1, 0, 1],
        [-1, 0, 1],
        [-1, 0, 1]
    ]
    
    print("   Input Image (5√ó5):")
    print("   (0=black, 255=white)")
    for row in image:
        print(f"   {row}")
    print()
    
    print("   Vertical Edge Filter (3√ó3):")
    for row in filter_vert:
        print(f"   {row}")
    print()
    
    # Perform convolution (simplified - one position)
    print("   Convolution Step-by-Step (at position row=1, col=1):")
    print()
    
    # Extract 3x3 region
    region = []
    for i in range(3):
        region.append(image[i][0:3])
    
    print("   Image region (3√ó3):")
    for row in region:
        print(f"     {row}")
    print()
    
    # Element-wise multiply and sum
    result = 0
    print("   Multiply filter √ó image:")
    for i in range(3):
        for j in range(3):
            product = filter_vert[i][j] * region[i][j]
            result += product
            print(f"     {filter_vert[i][j]:2d} √ó {region[i][j]:3d} = {product:4d}")
    
    print(f"\n   Sum: {result}")
    print(f"   This is the output value at position (1,1)")
    print()
    
    # Perform full convolution
    def convolve_2d(image: List[List[int]], kernel: List[List[int]]) -> List[List[int]]:
        """Simple 2D convolution (no padding)."""
        img_h, img_w = len(image), len(image[0])
        ker_h, ker_w = len(kernel), len(kernel[0])
        out_h = img_h - ker_h + 1
        out_w = img_w - ker_w + 1
        
        output = []
        for i in range(out_h):
            row = []
            for j in range(out_w):
                # Extract region
                value = 0
                for ki in range(ker_h):
                    for kj in range(ker_w):
                        value += image[i + ki][j + kj] * kernel[ki][kj]
                row.append(value)
            output.append(row)
        return output
    
    output = convolve_2d(image, filter_vert)
    
    print("   Full Convolution Output (3√ó3):")
    for row in output:
        print(f"   {row}")
    print()
    
    print("   üí° Interpretation:")
    print("   ‚Ä¢ High values (765): Strong vertical edge detected!")
    print("   ‚Ä¢ Low values (0, -255): No edge")
    print("   ‚Ä¢ Filter found the edge where dark meets bright")
    print()
    
    print("üîÑ What Happens When Filter Slides:")
    print()
    print("   Position 1 (left side):")
    print("   Filter sees: [0, 0, 0] ‚Üí No edge (output ‚âà 0)")
    print()
    print("   Position 2 (at edge):")
    print("   Filter sees: [0, 0, 255] ‚Üí Edge! (output = 765)")
    print()
    print("   Position 3 (right side):")
    print("   Filter sees: [255, 255, 255] ‚Üí No edge (output ‚âà 0)")
    print()
    
    print("üí° Multiple Filters = Multiple Feature Maps:")
    print()
    print("   Vertical edge filter ‚Üí Detects | edges")
    print("   Horizontal edge filter ‚Üí Detects ‚Äæ edges")
    print("   Diagonal edge filter ‚Üí Detects / edges")
    print()
    print("   Each filter creates one feature map")
    print("   32 filters ‚Üí 32 feature maps (rich representation!)")


# ============================================================================
# 3. CNN Architecture
# ============================================================================

def demo_cnn_architecture():
    """
    CNN Architecture: Stack of Conv, Pool, and FC layers
    
    INTUITION - The Manufacturing Assembly Line:
    
    Raw materials (image) ‚Üí Final product (classification)
    
    Station 1: Convolutional Layer
    "Extract features (edges, textures)"
    Like quality inspector checking for defects
    
    Station 2: Activation (ReLU)
    "Keep important features, discard noise"
    Like filter removing bad parts
    
    Station 3: Pooling
    "Reduce size, keep essential info"
    Like summarizer: 4 items ‚Üí 1 representative
    
    Station 4-6: Repeat
    "Build higher-level features"
    
    Final Station: Fully Connected
    "Make decision based on all features"
    Like manager reviewing reports, making final call
    
    Classic CNN (e.g., LeNet, AlexNet):
    
    Input Image (224√ó224√ó3)
        ‚Üì
    Conv Layer 1 (3√ó3 filters, 32 channels)
    ‚Üí Detects edges, basic patterns
    ‚Üí Output: 222√ó222√ó32
        ‚Üì
    ReLU Activation
    ‚Üí Remove negative values
        ‚Üì
    MaxPool (2√ó2)
    ‚Üí Reduce size by half
    ‚Üí Output: 111√ó111√ó32
        ‚Üì
    Conv Layer 2 (3√ó3 filters, 64 channels)
    ‚Üí Detects textures, shapes
    ‚Üí Output: 109√ó109√ó64
        ‚Üì
    ReLU + MaxPool
    ‚Üí Output: 54√ó54√ó64
        ‚Üì
    Conv Layer 3 (3√ó3 filters, 128 channels)
    ‚Üí Detects parts (ears, eyes)
    ‚Üí Output: 52√ó52√ó128
        ‚Üì
    ReLU + MaxPool
    ‚Üí Output: 26√ó26√ó128
        ‚Üì
    Flatten
    ‚Üí Convert to 1D vector: 26√ó26√ó128 = 86,528
        ‚Üì
    Fully Connected (1000 neurons)
    ‚Üí Combine features for classification
        ‚Üì
    Output (10 classes)
    ‚Üí Softmax ‚Üí Probabilities
    
    Real Example: Classifying Cat Photo
    
    Input: Cat photo
    ‚Üì
    Conv 1: Detects edges (whiskers, ears)
    ‚Üì
    Conv 2: Detects fur texture
    ‚Üì
    Conv 3: Detects cat parts (triangular ears!)
    ‚Üì
    FC: Combines evidence ‚Üí "It's a cat!" (95%)
    """
    print("\n" + "=" * 70)
    print("3. CNN Architecture")
    print("=" * 70)
    print()
    print("üí≠ INTUITION: Assembly Line Manufacturing")
    print()
    print("   Raw Material (Input Image)")
    print("        ‚Üì")
    print("   Station 1: Extract Features (Conv Layer)")
    print("   'Find edges, patterns'")
    print("        ‚Üì")
    print("   Station 2: Filter (ReLU)")
    print("   'Keep good parts'")
    print("        ‚Üì")
    print("   Station 3: Summarize (Pooling)")
    print("   'Reduce size, keep essentials'")
    print("        ‚Üì")
    print("   Repeat (Deeper features)")
    print("        ‚Üì")
    print("   Final Station: Decision (FC Layer)")
    print("   'Combine everything, classify'")
    print("        ‚Üì")
    print("   Final Product (Classification)")
    print()
    
    print("üèóÔ∏è Example CNN Architecture (for ImageNet):")
    print()
    
    layers = [
        ("Input", "224√ó224√ó3", "RGB image"),
        ("Conv1", "224√ó224√ó32", "32 filters, 3√ó3, detect edges"),
        ("ReLU", "224√ó224√ó32", "Remove negatives"),
        ("MaxPool", "112√ó112√ó32", "Downsample by 2"),
        ("Conv2", "112√ó112√ó64", "64 filters, detect textures"),
        ("ReLU", "112√ó112√ó64", "Remove negatives"),
        ("MaxPool", "56√ó56√ó64", "Downsample by 2"),
        ("Conv3", "56√ó56√ó128", "128 filters, detect parts"),
        ("ReLU", "56√ó56√ó128", "Remove negatives"),
        ("MaxPool", "28√ó28√ó128", "Downsample by 2"),
        ("Flatten", "100,352", "Convert to 1D vector"),
        ("FC1", "1,000", "Fully connected layer"),
        ("FC2", "10", "Output classes"),
        ("Softmax", "10", "Class probabilities"),
    ]
    
    print("   Layer          Output Shape        Description")
    print("   " + "-" * 65)
    for name, shape, desc in layers:
        print(f"   {name:12s}   {shape:15s}   {desc}")
    print()
    
    print("üìä What Each Layer Does:")
    print()
    print("   1Ô∏è‚É£  Convolutional Layer:")
    print("      ‚Ä¢ Applies filters to detect patterns")
    print("      ‚Ä¢ Parameters: filter_size, num_filters, stride")
    print("      ‚Ä¢ Example: 32 filters of 3√ó3 = 32 different patterns")
    print()
    print("   2Ô∏è‚É£  ReLU Activation:")
    print("      ‚Ä¢ Removes negative values (max(0, x))")
    print("      ‚Ä¢ Adds non-linearity")
    print("      ‚Ä¢ Fast, works well in practice")
    print()
    print("   3Ô∏è‚É£  MaxPooling:")
    print("      ‚Ä¢ Takes maximum in each region (e.g., 2√ó2)")
    print("      ‚Ä¢ Reduces spatial size (downsampling)")
    print("      ‚Ä¢ Provides translation invariance")
    print()
    print("   Example: MaxPool 2√ó2")
    print("   Input (4√ó4):        Output (2√ó2):")
    print("   [1  2  | 3  4]      [6  8]")
    print("   [5  6  | 7  8]  ‚Üí   [14 16]")
    print("   ------+------")
    print("   [9  10 | 11 12]")
    print("   [13 14 | 15 16]")
    print()
    print("   4Ô∏è‚É£  Fully Connected Layer:")
    print("      ‚Ä¢ Every neuron connects to every input")
    print("      ‚Ä¢ Combines all features for final decision")
    print("      ‚Ä¢ Usually at the end of network")
    print()
    
    print("üéØ Real Example: Cat Image Classification")
    print()
    print("   Input: 224√ó224 RGB cat photo")
    print()
    print("   After Conv1 (edge detection):")
    print("   ‚Ä¢ Detects whisker edges")
    print("   ‚Ä¢ Detects ear outlines")
    print("   ‚Ä¢ Detects fur boundaries")
    print()
    print("   After Conv2 (texture detection):")
    print("   ‚Ä¢ Combines edges ‚Üí Fur texture")
    print("   ‚Ä¢ Combines edges ‚Üí Striped patterns")
    print("   ‚Ä¢ Combines edges ‚Üí Smooth surfaces")
    print()
    print("   After Conv3 (part detection):")
    print("   ‚Ä¢ Combines textures ‚Üí Triangular ears!")
    print("   ‚Ä¢ Combines textures ‚Üí Whisker clusters")
    print("   ‚Ä¢ Combines textures ‚Üí Round eyes")
    print()
    print("   After FC Layer (decision):")
    print("   ‚Ä¢ Triangular ears? ‚úì")
    print("   ‚Ä¢ Whiskers? ‚úì")
    print("   ‚Ä¢ Fur texture? ‚úì")
    print("   ‚Üí Prediction: 'Cat' (95% confidence)")
    print()
    
    print("üí° Design Principles:")
    print()
    print("   1. Start with small filters (3√ó3 or 5√ó5)")
    print("   2. Increase channels as you go deeper")
    print("      (3 ‚Üí 32 ‚Üí 64 ‚Üí 128 ‚Üí 256)")
    print("   3. Use MaxPool to reduce spatial size")
    print("   4. Stack multiple conv layers before pooling")
    print("   5. End with fully connected layers")
    print()
    
    print("üöÄ Famous CNN Architectures:")
    print()
    print("   LeNet-5 (1998): Digit recognition, 5 layers")
    print("   AlexNet (2012): ImageNet winner, 8 layers, ReLU + dropout")
    print("   VGG-16 (2014): Very deep (16 layers), small 3√ó3 filters")
    print("   ResNet (2015): 50-152 layers, skip connections")
    print("   EfficientNet (2019): Optimized for efficiency")
    print()
    print("   Trend: Deeper networks + smart architectures = Better results")


# ============================================================================
# 4. Training Tips
# ============================================================================

def demo_training_tips():
    """
    Practical tips for training CNNs effectively.
    """
    print("\n" + "=" * 70)
    print("4. CNN Training Tips")
    print("=" * 70)
    print()
    
    print("üí° Data Augmentation (Critical for CNNs!):")
    print()
    print("   Problem: Need 1000s of labeled images (expensive!)")
    print()
    print("   Solution: Generate variations of existing images")
    print("   ‚Ä¢ Random rotation (¬±15¬∞)")
    print("   ‚Ä¢ Random flip (horizontal)")
    print("   ‚Ä¢ Random crop")
    print("   ‚Ä¢ Random brightness/contrast")
    print("   ‚Ä¢ Color jittering")
    print()
    print("   Result: 1,000 images ‚Üí 10,000+ variations!")
    print("   Impact: Reduces overfitting, improves generalization")
    print()
    
    print("üéØ Transfer Learning (The Secret Weapon):")
    print()
    print("   Instead of training from scratch:")
    print("   1. Start with pre-trained model (e.g., ResNet on ImageNet)")
    print("   2. Remove last layer")
    print("   3. Add your own classifier")
    print("   4. Fine-tune on your data")
    print()
    print("   Benefits:")
    print("   ‚Ä¢ Train with 100s of images instead of 1000s")
    print("   ‚Ä¢ Train in hours instead of days")
    print("   ‚Ä¢ Better accuracy (learns from ImageNet's 14M images)")
    print()
    print("   Real Example:")
    print("   Scratch: 70% accuracy, 2 days training")
    print("   Transfer learning: 95% accuracy, 2 hours training!")
    print()
    
    print("‚öôÔ∏è Optimization Tips:")
    print()
    print("   1Ô∏è‚É£  Batch Size:")
    print("      ‚Ä¢ Small (16-32): Better generalization, slower")
    print("      ‚Ä¢ Large (128-256): Faster training, needs more memory")
    print("      ‚Ä¢ Start with 32, increase if GPU has memory")
    print()
    print("   2Ô∏è‚É£  Learning Rate:")
    print("      ‚Ä¢ Too high: Loss explodes")
    print("      ‚Ä¢ Too low: Training too slow")
    print("      ‚Ä¢ Sweet spot: 0.001 (Adam) or 0.01 (SGD)")
    print("      ‚Ä¢ Use learning rate scheduler (decay over time)")
    print()
    print("   3Ô∏è‚É£  Optimizer:")
    print("      ‚Ä¢ SGD: Simple, needs tuning")
    print("      ‚Ä¢ Adam: Adaptive, works out of the box")
    print("      ‚Ä¢ Start with Adam (lr=0.001)")
    print()
    print("   4Ô∏è‚É£  Regularization:")
    print("      ‚Ä¢ Dropout: Randomly drop 20-50% of neurons")
    print("      ‚Ä¢ Batch Normalization: Normalize layer inputs")
    print("      ‚Ä¢ Weight Decay: L2 penalty on weights")
    print()
    
    print("üêõ Debugging Checklist:")
    print()
    print("   Loss not decreasing:")
    print("   ‚Ä¢ Learning rate too high/low")
    print("   ‚Ä¢ Bad initialization")
    print("   ‚Ä¢ Gradient vanishing/exploding")
    print()
    print("   Training good, validation bad (overfitting):")
    print("   ‚Ä¢ Add dropout")
    print("   ‚Ä¢ Add data augmentation")
    print("   ‚Ä¢ Reduce model complexity")
    print("   ‚Ä¢ Get more training data")
    print()
    print("   Training slow:")
    print("   ‚Ä¢ Use GPU (100x speedup!)")
    print("   ‚Ä¢ Increase batch size")
    print("   ‚Ä¢ Use mixed precision training")
    print("   ‚Ä¢ Use smaller image size")
    print()
    
    print("üìä Monitoring Training:")
    print()
    print("   Track these metrics:")
    print("   ‚Ä¢ Training loss (should decrease)")
    print("   ‚Ä¢ Validation loss (should decrease)")
    print("   ‚Ä¢ Validation accuracy (should increase)")
    print("   ‚Ä¢ Learning rate (if using scheduler)")
    print()
    print("   Good signs:")
    print("   ‚úÖ Both losses decreasing")
    print("   ‚úÖ Small gap between train and val loss")
    print("   ‚úÖ Accuracy improving")
    print()
    print("   Bad signs:")
    print("   ‚ùå Train loss much lower than val loss (overfitting)")
    print("   ‚ùå Loss increasing or NaN (instability)")
    print("   ‚ùå No improvement after many epochs (stuck)")


# ============================================================================
# Run All Demonstrations
# ============================================================================

def main():
    """Run all demonstrations."""
    print("\nüñºÔ∏è CNNs for Image Classification\n")
    print("Learn why CNNs dominate computer vision!")
    print()
    
    demo_why_cnns()
    demo_convolution()
    demo_cnn_architecture()
    demo_training_tips()
    
    print("\n" + "=" * 70)
    print("‚úÖ Key Takeaways")
    print("=" * 70)
    print("""
1. Why CNNs?
   - Dramatically fewer parameters than fully connected
   - Translation invariant (finds patterns anywhere)
   - Learns hierarchical features (edges ‚Üí shapes ‚Üí objects)

2. Convolution Operation:
   - Small filter slides over image
   - Detects patterns locally
   - Same filter reused everywhere (efficient!)

3. CNN Architecture:
   - Conv layers: Extract features
   - Pooling: Reduce size, provide invariance
   - FC layers: Make final decision
   - Stack deeper for better features

4. Training Tips:
   - Data augmentation: Generate variations
   - Transfer learning: Start with pre-trained model
   - Adam optimizer: lr=0.001
   - Dropout + BatchNorm: Prevent overfitting

Real Impact:
- ImageNet: 75% ‚Üí 95%+ accuracy (CNNs)
- Face recognition, self-driving cars, medical imaging
- Transfer learning: 100 images can be enough!

PyTorch Example:
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3)
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc = nn.Linear(64 * 54 * 54, 10)
    
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 54 * 54)
        x = self.fc(x)
        return x
```

Next: Transfer learning with pre-trained models!
""")


if __name__ == "__main__":
    main()
