"""
Testing Data Pipelines with pytest

Learn how to test data preprocessing, feature engineering, and ML pipelines.
Focus: Data transformations, pipeline steps, data validation.

Install: poetry add --group dev pytest pandas scikit-learn
Run: pytest unit_tests/03_testing_pipelines.py -v
"""

import pytest
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple
from dataclasses import dataclass


# ============================================================================
# 1. Why Test Data Pipelines?
# ============================================================================

def demo_why_test_pipelines():
    """
    Why testing data pipelines is critical.
    """
    print("=" * 70)
    print("1. Why Test Data Pipelines?")
    print("=" * 70)
    print()
    
    print("üí• REAL-WORLD HORROR STORIES:")
    print()
    print("   Story 1: The Missing Value Bug")
    print("   ‚Ä¢ Pipeline: fillna(0)")
    print("   ‚Ä¢ Bug: Some columns had -999 as missing")
    print("   ‚Ä¢ Result: Model learned -999 = valid value")
    print("   ‚Ä¢ Impact: 30% accuracy drop in production üíÄ")
    print("   ‚Ä¢ Cost: 2 weeks debugging + retrain model")
    print()
    print("   Story 2: The Feature Scaling Disaster")
    print("   ‚Ä¢ Pipeline: StandardScaler()")
    print("   ‚Ä¢ Bug: Forgot to save scaler parameters")
    print("   ‚Ä¢ Result: Different scaling in production")
    print("   ‚Ä¢ Impact: Predictions completely wrong üíÄ")
    print("   ‚Ä¢ Cost: Emergency rollback + model retrain")
    print()
    print("   Story 3: The Data Leakage Nightmare")
    print("   ‚Ä¢ Pipeline: Impute missing with mean")
    print("   ‚Ä¢ Bug: Calculated mean on entire dataset")
    print("   ‚Ä¢ Result: Test data leaked into training")
    print("   ‚Ä¢ Impact: 95% accuracy in dev, 60% in prod üíÄ")
    print("   ‚Ä¢ Cost: Model unusable, 3 weeks to fix")
    print()
    
    print("üéØ WHY PIPELINES ARE RISKY:")
    print()
    print("   1. Many Steps:")
    print("      Clean ‚Üí Impute ‚Üí Scale ‚Üí Encode ‚Üí Feature Engineer")
    print("      Any step can break!")
    print("   ")
    print("   2. Silent Failures:")
    print("      fillna(0) never crashes")
    print("      But might be wrong!")
    print("   ")
    print("   3. State Management:")
    print("      Fit on train, transform on test")
    print("      Easy to mix up!")
    print("   ")
    print("   4. Data Drift:")
    print("      Pipeline works on old data")
    print("      Fails on new data!")
    print()
    
    print("‚úÖ WHAT TESTS PREVENT:")
    print()
    print("   ‚Ä¢ Missing value handling bugs")
    print("   ‚Ä¢ Feature scaling errors")
    print("   ‚Ä¢ Data leakage")
    print("   ‚Ä¢ Schema mismatches")
    print("   ‚Ä¢ Type conversion errors")
    print("   ‚Ä¢ NaN/Inf in output")
    print("   ‚Ä¢ Feature name mismatches")
    print()
    
    print("üí∞ ROI OF PIPELINE TESTS:")
    print()
    print("   Without tests:")
    print("   ‚Ä¢ Bug found in production: 2 weeks debugging")
    print("   ‚Ä¢ Emergency fixes: 40 hours")
    print("   ‚Ä¢ Model retrain: 1 week")
    print("   ‚Ä¢ Lost revenue: $50,000")
    print()
    print("   With tests:")
    print("   ‚Ä¢ Bug found in dev: 10 minutes")
    print("   ‚Ä¢ Fix: 30 minutes")
    print("   ‚Ä¢ Lost revenue: $0")
    print()
    print("   ROI: 100:1 (Save 100x debugging time!) ‚úÖ")
    print()


# ============================================================================
# 2. Simple Data Pipeline
# ============================================================================

class DataPipeline:
    """
    Simple data preprocessing pipeline.
    """
    
    def __init__(self):
        self.is_fitted = False
        self.feature_means = {}
        self.feature_stds = {}
    
    def fit(self, df: pd.DataFrame) -> 'DataPipeline':
        """Fit pipeline on training data."""
        # Calculate statistics
        self.feature_means = df.select_dtypes(include=[np.number]).mean().to_dict()
        self.feature_stds = df.select_dtypes(include=[np.number]).std().to_dict()
        self.is_fitted = True
        return self
    
    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform data using fitted statistics."""
        if not self.is_fitted:
            raise ValueError("Pipeline not fitted. Call fit() first.")
        
        df_copy = df.copy()
        
        # Fill missing values with mean
        for col in self.feature_means:
            if col in df_copy.columns:
                df_copy[col].fillna(self.feature_means[col], inplace=True)
        
        # Standardize (z-score)
        for col in self.feature_stds:
            if col in df_copy.columns and self.feature_stds[col] > 0:
                df_copy[col] = (
                    (df_copy[col] - self.feature_means[col]) / self.feature_stds[col]
                )
        
        return df_copy
    
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Fit and transform in one step."""
        return self.fit(df).transform(df)


# ============================================================================
# 3. Testing Pipeline State
# ============================================================================

@pytest.fixture
def sample_data():
    """Fixture providing sample dataframe."""
    return pd.DataFrame({
        'age': [25, 30, np.nan, 40],
        'income': [50000, 60000, 70000, np.nan],
        'score': [0.8, 0.9, 0.7, 0.95]
    })


def test_pipeline_not_fitted_raises_error():
    """Test that unfitted pipeline raises error."""
    pipeline = DataPipeline()
    df = pd.DataFrame({'age': [25, 30]})
    
    with pytest.raises(ValueError, match="Pipeline not fitted"):
        pipeline.transform(df)


def test_pipeline_fit_sets_fitted_flag(sample_data):
    """Test that fit() sets is_fitted flag."""
    pipeline = DataPipeline()
    assert pipeline.is_fitted is False
    
    pipeline.fit(sample_data)
    assert pipeline.is_fitted is True


def test_pipeline_fit_calculates_statistics(sample_data):
    """Test that fit() calculates correct statistics."""
    pipeline = DataPipeline()
    pipeline.fit(sample_data)
    
    # Check means
    assert 'age' in pipeline.feature_means
    assert 'income' in pipeline.feature_means
    assert 'score' in pipeline.feature_means
    
    # Check specific values (approximately)
    expected_age_mean = (25 + 30 + 40) / 3  # NaN excluded
    assert pytest.approx(pipeline.feature_means['age'], abs=0.1) == expected_age_mean


def demo_testing_pipeline_state():
    """Demo testing pipeline state."""
    print("\n" + "=" * 70)
    print("2. Testing Pipeline State")
    print("=" * 70)
    print()
    
    print("üîí WHY STATE MATTERS:")
    print()
    print("   Stateful pipeline:")
    print("   1. fit(train_data)   ‚Üí Learn statistics")
    print("   2. transform(test_data) ‚Üí Apply statistics")
    print()
    print("   Bug example:")
    print("   pipeline.transform(test_data)  ‚Üê Not fitted!")
    print("   ‚Üí Wrong results or crash")
    print()
    
    print("‚úÖ WHAT TO TEST:")
    print()
    print("   1. Not Fitted Error:")
    print("      pipeline.transform(...) before fit()")
    print("      ‚Üí ValueError ‚úÖ")
    print("   ")
    print("   2. Fitted Flag:")
    print("      After fit(), is_fitted == True")
    print("   ")
    print("   3. Statistics Calculated:")
    print("      After fit(), means/stds exist")
    print("   ")
    print("   4. Statistics Correct:")
    print("      Verify calculated values")
    print()


# ============================================================================
# 4. Testing Data Transformations
# ============================================================================

def test_pipeline_fills_missing_values(sample_data):
    """Test that missing values are filled."""
    pipeline = DataPipeline()
    pipeline.fit(sample_data)
    
    # Transform data with missing values
    transformed = pipeline.transform(sample_data)
    
    # No missing values in numeric columns
    assert transformed['age'].isna().sum() == 0
    assert transformed['income'].isna().sum() == 0


def test_pipeline_standardizes_features(sample_data):
    """Test that features are standardized."""
    pipeline = DataPipeline()
    transformed = pipeline.fit_transform(sample_data)
    
    # Standardized features have mean ‚âà 0 and std ‚âà 1
    for col in ['age', 'income', 'score']:
        mean = transformed[col].mean()
        std = transformed[col].std()
        
        # Check mean close to 0
        assert pytest.approx(mean, abs=0.1) == 0.0
        
        # Check std close to 1 (if not constant)
        if std > 0.01:
            assert pytest.approx(std, abs=0.2) == 1.0


def test_pipeline_preserves_data_shape(sample_data):
    """Test that pipeline preserves data shape."""
    pipeline = DataPipeline()
    transformed = pipeline.fit_transform(sample_data)
    
    # Same shape
    assert transformed.shape == sample_data.shape
    
    # Same columns
    assert list(transformed.columns) == list(sample_data.columns)


def test_pipeline_preserves_data_types(sample_data):
    """Test that pipeline preserves numeric data types."""
    pipeline = DataPipeline()
    transformed = pipeline.fit_transform(sample_data)
    
    # All columns still numeric
    assert transformed['age'].dtype in [np.float64, np.int64]
    assert transformed['income'].dtype in [np.float64, np.int64]
    assert transformed['score'].dtype in [np.float64, np.int64]


def test_pipeline_no_nans_or_infs(sample_data):
    """Test that output has no NaN or Inf values."""
    pipeline = DataPipeline()
    transformed = pipeline.fit_transform(sample_data)
    
    # Check for NaN
    assert not transformed.isna().any().any()
    
    # Check for Inf
    assert not np.isinf(transformed.select_dtypes(include=[np.number])).any().any()


def demo_testing_transformations():
    """Demo testing data transformations."""
    print("\n" + "=" * 70)
    print("3. Testing Data Transformations")
    print("=" * 70)
    print()
    
    print("‚úÖ TRANSFORMATION TESTS:")
    print()
    print("   1. Missing Values:")
    print("      ‚Ä¢ Input: [1, 2, NaN, 4]")
    print("      ‚Ä¢ Output: [1, 2, 2.33, 4]  ‚Üê NaN filled")
    print("   ")
    print("   2. Standardization:")
    print("      ‚Ä¢ Mean ‚âà 0")
    print("      ‚Ä¢ Std ‚âà 1")
    print("   ")
    print("   3. Shape Preservation:")
    print("      ‚Ä¢ Input: (100, 5)")
    print("      ‚Ä¢ Output: (100, 5)  ‚Üê Same shape")
    print("   ")
    print("   4. No Invalid Values:")
    print("      ‚Ä¢ No NaN in output")
    print("      ‚Ä¢ No Inf in output")
    print("   ")
    print("   5. Data Types:")
    print("      ‚Ä¢ Numeric stays numeric")
    print("      ‚Ä¢ Categorical stays categorical")
    print()


# ============================================================================
# 5. Testing Pipeline Invariants
# ============================================================================

def test_pipeline_train_test_consistency(sample_data):
    """Test that train and test transforms are consistent."""
    # Split data
    train_data = sample_data.iloc[:2]
    test_data = sample_data.iloc[2:]
    
    # Fit on train
    pipeline = DataPipeline()
    pipeline.fit(train_data)
    
    # Transform both
    train_transformed = pipeline.transform(train_data)
    test_transformed = pipeline.transform(test_data)
    
    # Both should have same columns
    assert list(train_transformed.columns) == list(test_transformed.columns)
    
    # Both should have no NaNs
    assert not train_transformed.isna().any().any()
    assert not test_transformed.isna().any().any()


def test_pipeline_multiple_transforms_identical(sample_data):
    """Test that multiple transforms give same result."""
    pipeline = DataPipeline()
    pipeline.fit(sample_data)
    
    # Transform twice
    result1 = pipeline.transform(sample_data)
    result2 = pipeline.transform(sample_data)
    
    # Should be identical
    pd.testing.assert_frame_equal(result1, result2)


def test_pipeline_fit_idempotent(sample_data):
    """Test that fitting twice gives same result."""
    pipeline1 = DataPipeline()
    pipeline1.fit(sample_data)
    result1 = pipeline1.transform(sample_data)
    
    # Fit again
    pipeline2 = DataPipeline()
    pipeline2.fit(sample_data)
    pipeline2.fit(sample_data)  # Fit twice!
    result2 = pipeline2.transform(sample_data)
    
    # Should be same (within numerical precision)
    pd.testing.assert_frame_equal(result1, result2, atol=0.01)


def demo_testing_invariants():
    """Demo testing pipeline invariants."""
    print("\n" + "=" * 70)
    print("4. Testing Pipeline Invariants")
    print("=" * 70)
    print()
    
    print("üîç PIPELINE INVARIANTS:")
    print()
    print("   1. Train-Test Consistency:")
    print("      ‚Ä¢ Fit on train")
    print("      ‚Ä¢ Transform train and test")
    print("      ‚Ä¢ Both use same statistics ‚úÖ")
    print("   ")
    print("   2. Reproducibility:")
    print("      ‚Ä¢ transform(X) == transform(X)")
    print("      ‚Ä¢ Same input ‚Üí Same output")
    print("   ")
    print("   3. Idempotency:")
    print("      ‚Ä¢ fit(X) then fit(X) again")
    print("      ‚Ä¢ Second fit same as first")
    print()
    
    print("üí• COMMON BUGS CAUGHT:")
    print()
    print("   Bug 1: Refit on test data")
    print("   pipeline.fit(train)")
    print("   pipeline.fit(test)  ‚Üê WRONG! Overwrites statistics")
    print()
    print("   Bug 2: Different scaling")
    print("   train_scaled = scale(train)")
    print("   test_scaled = scale(test)  ‚Üê WRONG! Different scaling")
    print()
    print("   Bug 3: Stateful transforms")
    print("   result1 = pipeline.transform(X)")
    print("   result2 = pipeline.transform(X)  ‚Üê Different! (Bug)")
    print()


# ============================================================================
# 6. Testing Edge Cases
# ============================================================================

def test_pipeline_with_empty_dataframe():
    """Test pipeline with empty dataframe."""
    pipeline = DataPipeline()
    df_empty = pd.DataFrame()
    
    # Fit on empty should work (but useless)
    pipeline.fit(df_empty)
    assert pipeline.is_fitted is True


def test_pipeline_with_single_row():
    """Test pipeline with single row."""
    df_single = pd.DataFrame({'age': [25], 'income': [50000]})
    
    pipeline = DataPipeline()
    result = pipeline.fit_transform(df_single)
    
    # Should work
    assert result.shape == (1, 2)


def test_pipeline_with_constant_column():
    """Test pipeline with constant column."""
    df = pd.DataFrame({
        'age': [25, 30, 35],
        'constant': [1, 1, 1]  # No variance
    })
    
    pipeline = DataPipeline()
    result = pipeline.fit_transform(df)
    
    # Constant column stays constant (std=0, don't divide)
    assert result['constant'].std() == 0


def test_pipeline_with_all_missing():
    """Test pipeline with all missing values in a column."""
    df = pd.DataFrame({
        'age': [25, 30, 35],
        'missing': [np.nan, np.nan, np.nan]
    })
    
    pipeline = DataPipeline()
    result = pipeline.fit_transform(df)
    
    # All missing ‚Üí filled with NaN mean (which is NaN)
    # This might be a design choice
    assert result.shape == df.shape


def demo_testing_edge_cases():
    """Demo testing edge cases."""
    print("\n" + "=" * 70)
    print("5. Testing Edge Cases")
    print("=" * 70)
    print()
    
    print("üö® EDGE CASES:")
    print()
    print("   1. Empty DataFrame:")
    print("      ‚Ä¢ 0 rows, 0 columns")
    print("      ‚Ä¢ Should fit without error")
    print("   ")
    print("   2. Single Row:")
    print("      ‚Ä¢ Can't calculate std properly")
    print("      ‚Ä¢ Handle gracefully")
    print("   ")
    print("   3. Constant Column:")
    print("      ‚Ä¢ All values same")
    print("      ‚Ä¢ std = 0 ‚Üí Don't divide")
    print("   ")
    print("   4. All Missing:")
    print("      ‚Ä¢ Column all NaN")
    print("      ‚Ä¢ Can't impute with mean")
    print("   ")
    print("   5. Mixed Types:")
    print("      ‚Ä¢ Numeric + Categorical")
    print("      ‚Ä¢ Only process numeric")
    print()


# ============================================================================
# 7. Testing with Parametrize
# ============================================================================

@pytest.mark.parametrize("missing_strategy", ["mean", "median", "zero"])
def test_pipeline_different_imputation_strategies(missing_strategy):
    """Test pipeline with different imputation strategies."""
    # This would test different configurations
    # For now, just ensure it runs
    pass


@pytest.mark.parametrize("n_rows,n_cols", [
    (10, 3),
    (100, 5),
    (1000, 10),
])
def test_pipeline_with_different_sizes(n_rows, n_cols):
    """Test pipeline with different data sizes."""
    # Generate random data
    df = pd.DataFrame(
        np.random.randn(n_rows, n_cols),
        columns=[f'col{i}' for i in range(n_cols)]
    )
    
    pipeline = DataPipeline()
    result = pipeline.fit_transform(df)
    
    # Check shape preserved
    assert result.shape == (n_rows, n_cols)
    
    # Check no NaNs or Infs
    assert not result.isna().any().any()
    assert not np.isinf(result).any().any()


# ============================================================================
# Run Demonstrations
# ============================================================================

def main():
    """Run all demonstrations."""
    print("\nüß™ Testing Data Pipelines\n")
    
    demo_why_test_pipelines()
    demo_testing_pipeline_state()
    demo_testing_transformations()
    demo_testing_invariants()
    demo_testing_edge_cases()
    
    print("\n" + "=" * 70)
    print("‚úÖ Key Takeaways")
    print("=" * 70)
    print("""
1. Why Test Pipelines:
   - Silent failures common
   - Many transformation steps
   - State management errors
   - Data leakage risks
   - ROI: 100:1 (catch bugs early)

2. Pipeline State Tests:
   ‚úÖ Not fitted ‚Üí Error
   ‚úÖ After fit ‚Üí is_fitted = True
   ‚úÖ Statistics calculated correctly
   ‚úÖ Fit is idempotent

3. Transformation Tests:
   ‚úÖ Missing values filled
   ‚úÖ Features standardized (mean‚âà0, std‚âà1)
   ‚úÖ Shape preserved
   ‚úÖ Data types preserved
   ‚úÖ No NaN/Inf in output

4. Invariant Tests:
   ‚úÖ Train-test consistency
   ‚úÖ Reproducibility: transform(X) == transform(X)
   ‚úÖ Fit idempotent

5. Edge Cases:
   - Empty DataFrame
   - Single row
   - Constant column (std=0)
   - All missing values
   - Mixed data types

Testing Checklist:
```
Pipeline Tests:
‚ñ° Not fitted raises error
‚ñ° Fitted flag set after fit()
‚ñ° Statistics calculated correctly
‚ñ° Missing values handled
‚ñ° Features standardized
‚ñ° Shape preserved
‚ñ° Data types preserved
‚ñ° No NaN/Inf in output
‚ñ° Train-test consistency
‚ñ° Reproducible transforms
‚ñ° Idempotent fit
‚ñ° Empty DataFrame handled
‚ñ° Single row handled
‚ñ° Constant column handled
‚ñ° All missing handled
```

Common Bugs Prevented:
‚Ä¢ Data leakage (fit on test)
‚Ä¢ Wrong imputation strategy
‚Ä¢ Feature scaling errors
‚Ä¢ NaN propagation
‚Ä¢ Type conversion errors
‚Ä¢ Schema mismatches

Next Steps:
‚Üí 04_testing_apis.py (Test ML APIs)
‚Üí 05_data_validation.py (Validate input data)
""")


if __name__ == "__main__":
    main()
